{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "class URLValidator:\n",
        "    \"\"\"\n",
        "    A class to evaluate the credibility of a webpage using domain trust, content relevance,\n",
        "    fact-checking, bias detection, and citations, with SERP API integration for Google Scholar.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, serp_api_key: str):\n",
        "        self.serp_api_key = \"Your_SERP_API\"\n",
        "        self.similarity_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "        self.fake_news_classifier = pipeline(\n",
        "            \"text-classification\", model=\"mrm8488/bert-tiny-finetuned-fake-news-detection\"\n",
        "        )\n",
        "        self.sentiment_analyzer = pipeline(\n",
        "            \"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "        )\n",
        "\n",
        "    def fetch_page_content(self, url: str) -> str:\n",
        "        \"\"\"Fetch and extract text content from the given URL.\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            content = \" \".join([p.text.strip() for p in soup.find_all(\"p\") if p.text.strip()])\n",
        "            return content if content else \"\"\n",
        "        except requests.RequestException:\n",
        "            return \"\"\n",
        "\n",
        "    def get_domain_trust(self, url: str) -> int:\n",
        "        \"\"\"Determine the trustworthiness of the domain.\"\"\"\n",
        "        domain_scores = {\n",
        "            \"highly_trusted\": {\n",
        "                \"mayoclinic.org\": 95, \"nih.gov\": 95, \"who.int\": 95, \"bbc.com\": 85,\n",
        "                \"reuters.com\": 95, \"harvard.edu\": 95, \"stanford.edu\": 95,\n",
        "            },\n",
        "            \"trusted\": {\n",
        "                \"nytimes.com\": 85, \"sciencedaily.com\": 80, \"wired.com\": 80, \"arxiv.org\": 80,\n",
        "            },\n",
        "            \"moderately_trusted\": {\n",
        "                \"wikipedia.org\": 70, \"medium.com\": 60, \"healthline.com\": 65,\n",
        "            },\n",
        "            \"low_trust\": {\n",
        "                \"reddit.com\": 45, \"quora.com\": 40, \"buzzfeednews.com\": 45,\n",
        "            },\n",
        "            \"very_low_trust\": {\n",
        "                \"infowars.com\": 15, \"breitbart.com\": 20, \"theonion.com\": 15,\n",
        "            },\n",
        "        }\n",
        "\n",
        "        for trust_level, domains in domain_scores.items():\n",
        "            for domain, score in domains.items():\n",
        "                if domain in url:\n",
        "                    return score\n",
        "        return 35  # Default score for unknown domains\n",
        "\n",
        "    def compute_similarity_score(self, user_query: str, content: str) -> int:\n",
        "        \"\"\"Compute semantic similarity between the user query and webpage content.\"\"\"\n",
        "        if not content or not user_query.strip():\n",
        "            return 0\n",
        "        try:\n",
        "            content = content[:2000]\n",
        "            similarity = util.pytorch_cos_sim(\n",
        "                self.similarity_model.encode(user_query, normalize_embeddings=True),\n",
        "                self.similarity_model.encode(content, normalize_embeddings=True)\n",
        "            ).item()\n",
        "            return max(0, min(int(similarity * 100), 100))\n",
        "        except Exception as e:\n",
        "            print(f\"Error in compute_similarity_score: {e}\")\n",
        "            return 0\n",
        "\n",
        "    def check_facts(self, content: str) -> int:\n",
        "        \"\"\"Check facts in the content using a fact-check API.\"\"\"\n",
        "        if not content:\n",
        "            return 50\n",
        "        try:\n",
        "            api_url = f\"https://toolbox.google.com/factcheck/api/v1/claimsearch?query={content[:200]}\"\n",
        "            response = requests.get(api_url)\n",
        "            data = response.json()\n",
        "            return 90 if \"claims\" in data and data[\"claims\"] else 40\n",
        "        except:\n",
        "            return 50\n",
        "\n",
        "    def check_google_scholar(self, query: str) -> int:\n",
        "        \"\"\"Check Google Scholar for citations using SERP API.\"\"\"\n",
        "        try:\n",
        "            serp_api_url = \"https://serpapi.com/search.json\"\n",
        "            params = {\n",
        "                \"engine\": \"google_scholar\",\n",
        "                \"q\": query,\n",
        "                \"api_key\": self.serp_api_key\n",
        "            }\n",
        "            response = requests.get(serp_api_url, params=params)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if \"organic_results\" in data:\n",
        "                citation_counts = [\n",
        "                    int(result.get(\"cited_by\", {}).get(\"value\", 0))\n",
        "                    for result in data[\"organic_results\"]\n",
        "                    if \"cited_by\" in result\n",
        "                ]\n",
        "                total_citations = sum(citation_counts)\n",
        "                return max(35, min(total_citations * 2, 100))\n",
        "            else:\n",
        "                return 35\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching Google Scholar citations: {e}\")\n",
        "            return 35\n",
        "\n",
        "    def detect_bias(self, content: str) -> int:\n",
        "        \"\"\"Detect bias in the content using sentiment analysis.\"\"\"\n",
        "        if not content:\n",
        "            return 50\n",
        "        sentiment_result = self.sentiment_analyzer(content[:512])[0]\n",
        "        label = sentiment_result[\"label\"]\n",
        "        if label == \"POSITIVE\":\n",
        "            return 90\n",
        "        elif label == \"NEGATIVE\":\n",
        "            return 30\n",
        "        else:\n",
        "            return 60\n",
        "\n",
        "    def get_star_rating(self, score: float) -> tuple:\n",
        "        \"\"\"Convert a score (0-100) into a 1-5 star rating.\"\"\"\n",
        "        stars = max(1, min(5, round(score / 20)))\n",
        "        return stars, \"⭐\" * stars\n",
        "\n",
        "    def generate_explanation(self, domain_trust, similarity_score, fact_check_score, bias_score, citation_score) -> str:\n",
        "        \"\"\"Generate an explanation for the score.\"\"\"\n",
        "        reasons = []\n",
        "        if domain_trust < 50:\n",
        "            reasons.append(\"The source has low domain authority.\")\n",
        "        if similarity_score < 50:\n",
        "            reasons.append(\"The content is not highly relevant to your query.\")\n",
        "        if fact_check_score < 50:\n",
        "            reasons.append(\"Limited fact-checking verification found.\")\n",
        "        if bias_score < 50:\n",
        "            reasons.append(\"Potential bias detected in the content.\")\n",
        "        if citation_score < 50:\n",
        "            reasons.append(\"Few citations found for this content.\")\n",
        "        return \" \".join(reasons) if reasons else \"This source is highly credible and relevant.\"\n",
        "\n",
        "    def rate_url_validity(self, user_query: str, url: str) -> dict:\n",
        "        \"\"\"Evaluate the validity of a webpage.\"\"\"\n",
        "        content = self.fetch_page_content(url)\n",
        "        domain_trust = self.get_domain_trust(url)\n",
        "        similarity_score = self.compute_similarity_score(user_query, content)\n",
        "        fact_check_score = self.check_facts(content)\n",
        "        bias_score = self.detect_bias(content)\n",
        "        citation_score = self.check_google_scholar(user_query)\n",
        "\n",
        "        final_score = (\n",
        "            (0.4 * domain_trust) +\n",
        "            (0.3 * similarity_score) +\n",
        "            (0.15 * fact_check_score) +\n",
        "            (0.1 * bias_score) +\n",
        "            (0.15 * citation_score)\n",
        "        )\n",
        "\n",
        "        stars, icon = self.get_star_rating(final_score)\n",
        "        explanation = self.generate_explanation(domain_trust, similarity_score, fact_check_score, bias_score, citation_score)\n",
        "\n",
        "        return {\n",
        "            \"scores\": {\n",
        "                \"Domain Trust\": domain_trust,\n",
        "                \"Content Relevance\": similarity_score,\n",
        "                \"Fact-Check\": fact_check_score,\n",
        "                \"Bias\": bias_score,\n",
        "                \"Citations\": citation_score,\n",
        "                \"Final Score\": final_score\n",
        "            },\n",
        "            \"stars\": {\"rating\": stars, \"icon\": icon},\n",
        "            \"explanation\": explanation\n",
        "        }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    serp_api_key = \"Your_SERP_API\"  # Replace with your SERP API key\n",
        "    validator = URLValidator(serp_api_key)\n",
        "    user_query = \"AI advancements in 2025\"\n",
        "    test_url = \"https://www.bbc.com/news/technology-60122274\"\n",
        "    result = validator.rate_url_validity(user_query, test_url)\n",
        "    pprint(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvvOjbroTNET",
        "outputId": "17d261f1-9909-4259-88b6-5addf17fcfcb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'explanation': 'The content is not highly relevant to your query. Few '\n",
            "                'citations found for this content.',\n",
            " 'scores': {'Bias': 50,\n",
            "            'Citations': 35,\n",
            "            'Content Relevance': 0,\n",
            "            'Domain Trust': 85,\n",
            "            'Fact-Check': 50,\n",
            "            'Final Score': 51.75},\n",
            " 'stars': {'icon': '⭐⭐⭐', 'rating': 3}}\n"
          ]
        }
      ]
    }
  ]
}